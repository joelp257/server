# -*- coding: utf-8 -*-
"""clusterdiabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dVuYSSCGj52G8isR2GDeyp3CKe61VyWC
"""

import numpy as np
import pandas as pd
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer  # Import SimpleImputer instead of Imputer
from sklearn import metrics
from sklearn.model_selection import RandomizedSearchCV


data = pd.read_csv("diabetes.csv")

# Explore the data
print("Shape of the dataset:", data.shape)
print("First 5 rows of the dataset:\n", data.head())

X= data.iloc[:,:-1].values

# prompt: apply clustring on x and compare the result

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Apply K-means clustering with different number of clusters
kmeans_models = [KMeans(n_clusters=k) for k in range(2, 11)]
for model in kmeans_models:
  model.fit(X)
  print(f"Number of clusters: {model.n_clusters}")
  print(f"Inertia: {model.inertia_}")

# Compare the results using the elbow method
plt.plot([model.n_clusters for model in kmeans_models], [model.inertia_ for model in kmeans_models])
plt.xlabel("Number of clusters")
plt.ylabel("Inertia")
plt.show()

model=kmeans_models[1]

# prompt: visualize the output clusters after applying pca

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Reduce dimensionality with PCA
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)

# Visualize the clusters after applying PCA
plt.figure(figsize=(8, 6))

for i in range(model.n_clusters):
  cluster_data = X_reduced[model.labels_ == i]
  plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f"Cluster {i+1}")

plt.legend()
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Visualizing Clusters after Applying PCA")
plt.show()